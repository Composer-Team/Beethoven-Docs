"use strict";(self.webpackChunkbeethoven_docs=self.webpackChunkbeethoven_docs||[]).push([[6085],{341:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>l,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"type":"mdx","permalink":"/Beethoven-Docs/Beethoven/HW/","source":"@site/src/pages/Beethoven/HW/index.md","title":"Beethoven Hardware Stack","description":"A design of an accelerator is broken down into two parts.","frontMatter":{},"unlisted":false}');var r=a(4848),i=a(8453),o=a(5537),s=a(9329);const l={},c="Beethoven Hardware Stack",d={},h=[{value:"A Basic Example",id:"a-basic-example",level:2},{value:"Boilerplate",id:"boilerplate",level:3},{value:"Host-Accelerator Communication",id:"host-accelerator-communication",level:3},{value:"Adding Memory Interfaces",id:"adding-memory-interfaces",level:3},{value:"Full Implementation",id:"full-implementation",level:3},{value:"Building For A Target Platform",id:"building-for-a-target-platform",level:3},{value:"Memory Interfaces",id:"memory-interfaces",level:2},{value:"Memory Read and Write Channels",id:"memory-read-and-write-channels",level:3},{value:"Configurations",id:"configurations",level:4},{value:"Accelerator Core Interface",id:"accelerator-core-interface",level:4},{value:"Transaction Waveform",id:"transaction-waveform",level:4},{value:"Transaction Parallelism",id:"transaction-parallelism",level:4},{value:"On-Chip Memory (Scratchpad)",id:"on-chip-memory-scratchpad",level:3},{value:"Configuration",id:"configuration",level:4},{value:"On-Chip Memory (User-Managed)",id:"on-chip-memory-user-managed",level:3},{value:"Host Interface",id:"host-interface",level:2},{value:"AccelCommand",id:"accelcommand",level:4},{value:"AccelResponse",id:"accelresponse",level:4},{value:"Behavior of BeethovenIO",id:"behavior-of-beethovenio",level:4},{value:"Configuration + Build",id:"configuration--build",level:2},{value:"Building your Accelerator",id:"building-your-accelerator",level:4},{value:"Platforms",id:"platforms",level:2},{value:"Current Platforms",id:"current-platforms",level:4}];function u(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"beethoven-hardware-stack",children:"Beethoven Hardware Stack"})}),"\n",(0,r.jsxs)(n.p,{children:["A design of an accelerator is broken down into two parts.\nFirst, there is the functional unit implementation, the core.\nYou would typically implement this in your HDL of choice.\nWe are huge fans of ",(0,r.jsx)(n.a,{href:"https://www.chisel-lang.org",children:"Chisel HDL"}),", but we do understand the necessity of [System]Verilog,\nso we have added ",(0,r.jsx)(n.a,{href:"/Beethoven/HW/Verilog",children:"various utilities"})," to make it easier to integrate external Verilog modules into your design."]}),"\n",(0,r.jsxs)(n.p,{children:["Second, there is the ",(0,r.jsx)(n.a,{href:"/Beethoven/HW/#accelerator-configuration-and-building",children:"accelerator configuration"}),".\nThe configuration informs Beethoven ",(0,r.jsx)(n.em,{children:"how"})," to build your accelerator:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"What cores do you want in your design?"}),"\n",(0,r.jsx)(n.li,{children:"How many of each?"}),"\n",(0,r.jsx)(n.li,{children:"How are they connected to memory?"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Before we dive into the configuration, let's look at a simple accelerator core implementation."}),"\n",(0,r.jsx)(n.h2,{id:"a-basic-example",children:"A Basic Example"}),"\n",(0,r.jsx)(n.p,{children:"As an example, let's look at how we might implement a vector addition kernel in Beethoven."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"// C++ implementation for Vector addition\nvoid vector_add(int *a, int *b, int *out, int len) {\n    for (int i = 0; i < len; ++i)\n        out[i] = a[i] + b[i];\n}\n\nint main() {\n    int array_len = 1024;\n    int *a   = (int*)malloc(sizeof(int) * array_len);\n    int *b   = (int*)malloc(sizeof(int) * array_len);\n    int *out = (int*)malloc(sizeof(int) * array_len);\n    // initialize vectors\n    vector_add(a, b, out, array_len);\n    return 0;\n}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["We can start by implementing a module for performing the addition itself.\nBeethoven is designed in Chisel HDL, but if you prefer Verilog, you can\nintegrate Verilog code into Chisel using its ",(0,r.jsx)(n.a,{href:"https://www.chisel-lang.org/docs/explanations/blackboxes",children:"Blackbox"})," abstraction."]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"Chisel",label:"Chisel",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"class VectorAdd extends Module {\n  val io = IO(new Bundle {\n    val vec_a = Flipped(Decoupled(UInt(32.W)))\n    val vec_b = Flipped(Decoupled(UInt(32.W)))\n    val vec_out = Decoupled(UInt(32.W))\n  })\n  // only consume an element when everyone's ready to move\n  val can_consume = io.vec_a.valid && io.vec_b.valid && io.vec_out.ready\n  io.vec_out.valid := can_consume\n  io.vec_a.ready := can_consume\n  io.vec_b.ready := can_consume\n  io.vec_out.bits := io.vec_a.bits + io.vec_b.bits\n}\n"})})}),(0,r.jsx)(s.A,{value:"Verilog",label:"Verilog",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-verilog",children:"module VectorAdd (\n\tinput clk,\n\tinput reset,\n\tinput [31:0]  vec_a_bits,\n\tinput \t      vec_a_valid,\n\toutput\t\t  vec_a_ready,\n\tinput [31:0]  vec_b_bits,\n\tinput \t\t  vec_b_valid,\n\toutput\t\t  vec_b_ready,\n\toutput [31:0] vec_out_bits,\n\toutput \t\t  vec_out_valid,\n\tinput\t\t  vec_out_ready );\nwire can_consume = vec_a_valid && vec_b_valid && vec_out_ready;\n\nassign vec_out_bits = vec_a_bits + vec_b_bits;\n\nassign vec_out_valid = can_consume;\nassign vec_a_ready = can_consume;\nassign vec_b_ready = can_consume;\n\nendmodule\n"})})})]}),"\n",(0,r.jsxs)(n.p,{children:["Now that we have the addition implemented, how would we go about using this on real hardware?\nThe reality: it depends. The hardware you have is likely going to have a number of general purpose\nmemory interfaces. You'll need to provide addresses and a variety of protocol-specific metadata to\naccess your input vectors and write your output vector. Some examples of how one would do this\nusing general purpose protocols can be seen ",(0,r.jsx)(n.a,{href:"https://github.com/aws/aws-fpga/tree/f2/hdk/cl/examples/cl_mem_perf",children:"here"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Using these general-purpose protocols typically distracts from your core implementation because\nstrict compliance with the protocol and managing the ",(0,r.jsx)(n.em,{children:"physical"})," realities of the protocol (i.e., it\nmay have a fixed location on hardware) has little to do with your implementation. Let's take a\nlook at how we can use Beethoven abstractions to simplify our vector addition kernel."]}),"\n",(0,r.jsx)(n.h3,{id:"boilerplate",children:"Boilerplate"}),"\n",(0,r.jsx)(n.p,{children:"First, let's start with the boilerplate. For each Beethoven Core, you have a hardware implementation and\nan associated Configuration. Click on the tabs to see how we modify the implementation and configuration\nat each step."}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"Implementation",label:"Implementation",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"import chisel3._\nimport chisel3.util._\nimport beethoven._\n\nclass VectorAddCore()(implicit p: Parameters) extends AcceleratorCore {\n\t// implementation goes here\n}\n"})})}),(0,r.jsx)(s.A,{value:"Configuration",label:"Configuration",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'class VecAddConfig extends AcceleratorConfig(\n\tAcceleratorSystemConfig(\n\t\tnCores = 1,\n\t\tname = "myVectorAdd",\n\t\tmoduleConstructor = ModuleBuilder(p => new VectorAdd()(p))\n\t)\n)\n'})})})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"AcceleratorCore"})," is the top-level Beethoven abstraction for a user's design. You can modularize\nyour implementation in whatever fashion you'd like, but the module that you plan to expose to the\ntop-level memory interfaces needs to be an ",(0,r.jsx)(n.code,{children:"AcceleratorCore"}),".\nEach ",(0,r.jsx)(n.code,{children:"AcceleratorCore"})," has an associated ",(0,r.jsx)(n.code,{children:"AcceleratorConfig"})," that describes some high-level\ndetails that allow you to provide some high-level build parameters for your accelerator. One that\nyou can see here is ",(0,r.jsx)(n.code,{children:"nCores"}),". You can increase the number of independent cores on your accelerator\nby simply increasing this parameter."]}),"\n",(0,r.jsx)(n.h3,{id:"host-accelerator-communication",children:"Host-Accelerator Communication"}),"\n",(0,r.jsxs)(n.p,{children:["Next, we need to get the addresses for each of our vectors. The host CPU will need to send these\nover to the accelerator. To expose an accelerator function to the CPU, we expose a ",(0,r.jsx)(n.code,{children:"BeethovenIO"}),"\nin a similar way to ",(0,r.jsx)(n.code,{children:"IO()"})," in Chisel."]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"Implementation",label:"Implementation",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'// inside the AcceleratorCore\nval my_io = BeethovenIO(new AccelCommand("vector_add") {\n\tval vec_a_addr = Address()\n\tval vec_b_addr = Address()\n\tval vec_out_addr = Address()\n\tval vector_length = UInt(32.W)\n}, EmptyAccelResponse())\n'})})}),(0,r.jsx)(s.A,{value:"Configuration",label:"Configuration",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'class VecAddConfig extends AcceleratorConfig(\n        AcceleratorSystemConfig(\n                nCores = 1,\n                name = "myVectorAdd",\n                moduleConstructor = ModuleBuilder(p => new VectorAdd()(p))\n        )\n)\n'})})}),(0,r.jsx)(s.A,{value:"c",label:"Generated C++",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"namespace myVectorAdd {\n        beethoven::response_handle<bool> vector_add(\n\t\tuint16_t core_id,\n\t\tuint32_t vector_length,\n\t\tbeethoven::remote_ptr vec_a_addr,\n\t\tbeethoven::remote_ptr vec_b_addr,\n\t\tbeethoven::remote_ptr vec_out_addr);\n};\n"})})})]}),"\n",(0,r.jsxs)(n.p,{children:["The above snippet does several things.\nFirst, the command and response are both provided with names.\nThe name ",(0,r.jsx)(n.code,{children:"vector_add"}),", allows Beethoven to generate a software interface for your code\nthat will be called ",(0,r.jsx)(n.code,{children:"vector_add."}),"\nThis function will take in the the arguments as specified and return an acknowledgement.\nResponses can also carry payload, but we exclude that functionality for simplicity in this example.\nSecond, you'll notice ",(0,r.jsx)(n.code,{children:"Address()"})," is not a typical Verilog or Chisel type. We provide\nit to abstract away from platform-specific address-widths and provide a uniform interface."]}),"\n",(0,r.jsxs)(n.p,{children:["To read more about the full specification of ",(0,r.jsx)(n.code,{children:"BeethovenIO"}),", click ",(0,r.jsx)(n.a,{href:"#host-interface",children:"here"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"adding-memory-interfaces",children:"Adding Memory Interfaces"}),"\n",(0,r.jsxs)(n.p,{children:["Now that we have a way of obtaining the necessary function arguments from the host, we need to read\nour operands from memory. We can do this by declaring a ",(0,r.jsx)(n.code,{children:"Reader"}),". Usually you would have to read up\non the available interfaces for your platform - here, there's no need, just declare them."]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"impl",label:"Implementation",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'// inside AcceleratorCore\nval vec_a_reader = getReaderModule("vec_a")\nval vec_b_reader = getReaderModule("vec_b")\nval vec_out_writer = getWriterModule("vec_out")\n'})})}),(0,r.jsx)(s.A,{value:"config",label:"Configuration",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'class VecAddConfig extends AcceleratorConfig(\n        AcceleratorSystemConfig(\n                nCores = 1,\n                name = "myVectorAdd",\n                moduleConstructor = ModuleBuilder(p => new VectorAdd()(p)),\n\t\tmemoryChannelConfig = List(\n\t\t\tReadChannelConfig("vec_a", dataBytes = 4),\n\t\t\tReadChannelConfig("vec_b", dataBytes = 4),\n\t\t\tWriteChannelConfig("vec_out", dataBytes = 4)\n\t\t)\n        )\n)\n'})})})]}),"\n",(0,r.jsxs)(n.p,{children:["For each reader/writer, the physical data bus width is specified in the configuration.\nThese can be made arbitrarily large or small with some restrictions. Read more ",(0,r.jsx)(n.a,{href:"#memory-interfaces",children:"here"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"full-implementation",children:"Full Implementation"}),"\n",(0,r.jsx)(n.p,{children:"Finally, we have all of the primitives we need to connect our vector addition module and\nuse it on real hardware.\nBelow, you can see the full implementation."}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"impl",label:"Implementation",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'import chisel3._\nimport chisel3.util._\nimport beethoven._\nimport beethoven.common._\nimport chipsalliance.rocketchip.config.Parameters\n\nclass VectorAddCore()(implicit p: Parameters) extends AcceleratorCore {\n  val my_io = BeethovenIO(new AccelCommand("vector_add") {\n    val vec_a_addr = Address()\n    val vec_b_addr = Address()\n    val vec_out_addr = Address()\n    val vector_length = UInt(32.W)\n  }, EmptyAccelResponse())\n\n  val vec_a_reader = getReaderModule("vec_a")\n  val vec_b_reader = getReaderModule("vec_b")\n  val vec_out_writer = getWriterModule("vec_out")\n\n  val vec_length_bytes = my_io.req.bits.vector_length * 4.U\n\n  // from our previously defined module\n  val dut = Module(new VectorAdd())\n\n  /**\n   * provide sane default values\n   */\n  my_io.req.ready := false.B\n  my_io.resp.valid := false.B\n  // .fire is a Chisel-ism for "ready && valid"\n  vec_a_reader.requestChannel.valid := my_io.req.fire\n  vec_a_reader.requestChannel.bits.addr := my_io.req.bits.vec_a_addr\n  vec_a_reader.requestChannel.bits.len := vec_length_bytes\n\n  vec_b_reader.requestChannel.valid := my_io.req.fire\n  vec_b_reader.requestChannel.bits.addr := my_io.req.bits.vec_b_addr\n  vec_b_reader.requestChannel.bits.len := vec_length_bytes\n\n  vec_out_writer.requestChannel.valid := my_io.req.fire\n  vec_out_writer.requestChannel.bits.addr := my_io.req.bits.vec_out_addr\n  vec_out_writer.requestChannel.bits.len := vec_length_bytes\n\n  vec_a_reader.dataChannel.data.ready := false.B\n  vec_b_reader.dataChannel.data.ready := false.B\n  vec_out_writer.dataChannel.data.valid := false.B\n  vec_out_writer.dataChannel.data.bits := DontCare\n\n  dut.io.vec_a <> vec_a_reader.dataChannel.data\n  dut.io.vec_b <> vec_b_reader.dataChannel.data\n  dut.io.vec_out <> vec_out_writer.dataChannel.data\n\n  // state machine\n  val s_idle :: s_working :: s_finish :: Nil =  Enum(3)\n  val state = RegInit(s_idle)\n\n  when (state === s_idle) {\n    my_io.req.ready := vec_a_reader.requestChannel.ready &&\n      vec_b_reader.requestChannel.ready &&\n      vec_out_writer.requestChannel.ready\n    when (my_io.req.fire) {\n      state := s_working\n    }\n  }.elsewhen(state === s_working) {\n    // when the writer has finished writing the final datum,\n    // isFlushed will be driven high\n    when (vec_out_writer.dataChannel.isFlushed) {\n      state := s_finish\n    }\n  }.otherwise {\n    my_io.resp.valid := true.B\n    when (my_io.resp.fire) {\n      state := s_idle\n    }\n  }\n}\n'})})}),(0,r.jsx)(s.A,{value:"config",label:"Configuration",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'class VecAddConfig extends AcceleratorConfig(\n        AcceleratorSystemConfig(\n                nCores = 1,\n                name = "myVectorAdd",\n                moduleConstructor = ModuleBuilder(p => new VectorAddCore()(p)),\n                memoryChannelConfig = List(\n                        ReadChannelConfig("vec_a", dataBytes = 4),\n                        ReadChannelConfig("vec_b", dataBytes = 4),\n                        WriteChannelConfig("vec_out", dataBytes = 4)\n                )\n        )\n)\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"building-for-a-target-platform",children:"Building For A Target Platform"}),"\n",(0,r.jsxs)(n.p,{children:["Now we have a full implementation of an accelerator that we'll be able to use and\ndeploy on real hardware! The final step is to build it. With the following code and\nsome basic environment setup, we can build, simulate, and synthesize our accelerator\nfor FPGA. All that is necessary is the ",(0,r.jsx)(n.code,{children:"BuildMode"})," and the target platform, Beethoven\nhandles the rest."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"object VectorAddConfig extends BeethovenBuild(new VectorAddConfig,\n  buildMode = BuildMode.Synthesis,\n  platform = new AWSF2Platform)\n"})}),"\n",(0,r.jsx)(n.p,{children:"In this example we've shown an example of how we would deploy an accelerator with a\nvector addition core. However, we can build far more complex accelerators, with different\ncore implementations of the same accelerator and with many more cores of each type."}),"\n",(0,r.jsx)(n.h2,{id:"memory-interfaces",children:"Memory Interfaces"}),"\n",(0,r.jsxs)(n.p,{children:["Beethoven currently allows the programmer to declare read ports, write ports, and scratchpad memories.\nThese interfaces are intended to communicate with external memory (DRAM). We discuss how to communicate\nbetween other cores on-chip ",(0,r.jsx)(n.a,{href:"/Beethoven/HW/cross-core",children:"here"})]}),"\n",(0,r.jsx)(n.h3,{id:"memory-read-and-write-channels",children:"Memory Read and Write Channels"}),"\n",(0,r.jsx)(n.p,{children:"Read channels and other Beethoven memory interfaces are structured as request channel/data channel pairs\nand declared in the accelerator configuration.\nThe programmer can declare an arbitrary number of memory channels."}),"\n",(0,r.jsx)(n.h4,{id:"configurations",children:"Configurations"}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"config",label:"Reader Config",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class ReadChannelConfig(name: String,\n                             dataBytes: Int,\n                             nChannels: Int = 1,\n                             maxInFlightTxs: Option[Int] = None,\n                             bufferSizeBytesMin: Option[Int] = None)\n"})})}),(0,r.jsx)(s.A,{value:"wconfig",label:"Writer Config",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class WriteChannelConfig(name: String,\n                             dataBytes: Int,\n                             nChannels: Int = 1,\n                             maxInFlightTxs: Option[Int] = None,\n                             bufferSizeBytesMin: Option[Int] = None)\n"})})})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"name"}),": This should be a unique identifier within this accelerator core"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataBytes"}),": the width of the physical data bus in bytes. All memory transactions must be a multiple of the width\nof the data bus. The width of the data bus may differ from other readers/writers in the core and may\nalso differ from the width of the FPGA's memory bus."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nChannels"}),": The number of parallel request/data channel pairs associated with the unique ",(0,r.jsx)(n.code,{children:"name"})," identifier. This\nmay be useful if a number of independent channels serve a similar purpose or the number of parallel\nread transactions varies with a configuration parameter."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"maxInFlightTxs"}),": This is a performance parameter that can impact the maximum throughput of a channel  (see ",(0,r.jsx)(n.a,{href:"#transaction-parallelism",children:"here"}),").\nInternally, we initialize this to a sensible value provided by the platform developer, but if you\ndesire higher throughput, you can set this to a higher value. Larger values may make it harder to\nachieve timing closure inside the reader."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"bufferSizeBytesMin"}),": The minimum size of the data buffer inside the reader. We initialize this to a value specified\nby the maximum number of in flight transactions and the maximum transaction size. However, if your\napplication may benefit from a larger buffer size, then you can increase this. One such instance may\nbe an application with low average throughput (reducing the ",(0,r.jsx)(n.code,{children:"maxInFlightTxs"})," parameter), but with brief\nintervals of extremely high throughput. In such moments, you would not want to experience DRAM\nread latencies and would ideally want the data ready at once."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This should be provided inside the configuration for your accelerator core if you wish to use a read channel."}),"\n",(0,r.jsx)(n.h4,{id:"accelerator-core-interface",children:"Accelerator Core Interface"}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"rhw",label:"Fetch a Reader",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"// fetch the reader channel from your hardware\ndef getReaderModule(name: String, idx: Int = 0): ReaderModuleChannel\n"})})}),(0,r.jsx)(s.A,{value:"rret",label:"Reader Channel Type",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class ReaderModuleChannel(\n    requestChannel: DecoupledIO[ChannelTransactionBundle],\n    dataChannel: DataChannelIO)\n"})})}),(0,r.jsx)(s.A,{value:"whw",label:"Fetch a Writer",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"// fetch the writer channel from your hardware\ndef getWriterModule(name: String,\n                    idx: Int = 0): WriterModuleChannel\n"})})}),(0,r.jsx)(s.A,{value:"wret",label:"Writer Channel Type",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class WriterModuleChannel(\n    requestChannel: DecoupledIO[ChannelTransactionBundle],\n    dataChannel: WriterDataChannelIO)\n"})})})]}),"\n",(0,r.jsx)(n.p,{children:"For fetching a reader/writer from the accelerator core context, you'll need to specify the name of the channel\nand, optionally, the index corresponding to the stream that you want."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"name"}),": this corresponds to the name of the reader/writer in your configuration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"idx"}),": if you specified a multi-channel reader/writer, then you can specify which channel you are fetching. There is also\nthe ",(0,r.jsx)(n.code,{children:"getReaderModules"})," and ",(0,r.jsx)(n.code,{children:"getWriterModules"})," functions for fetching all channels at once."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Each of these functions returns an object containing the request and data channels for your reader/writer.\nThe request channel allows the programmer to ",(0,r.jsx)(n.em,{children:"launch"})," a transaction for the reader or writer. Memory transactions operate\nat byte-granularity and the addresses/lengths must be aligned to size of the data bus. For instance, a reader with a\n4-byte data bus must only launch 4B-aligned transactions."]}),"\n",(0,r.jsx)(n.p,{children:"The request channel is identical for readers and writers."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"requestChannel.valid"})," (Output): drive this signal high to start a new transaction. The transaction will begin only\nwhen the ready and valid are high together on the rising clock edge."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"requestChannel.ready"})," (Input): This signal will be driven high when the reader is ready to begin a new transaction.\nIn-progress transactions cannot be interrupted an must be fully consumed before the reader is made ready again."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"requestChannel.bits.address"}),": the starting address for the transaction."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"requestChannel.bits.len"}),": the length of a transaction in bytes. This may be made arbitrarily long."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Reader Data Channel"}),": The data channel for the  will begin to provide valid data an indeterminate amount of time after the start of the\ntransaction. You must drive the input signals."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.inProgress"})," (Output): This is driven high iff there is an in-progress transaction still active."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.data.valid"})," (Output): This bit is driven high when there is valid data from memory on ",(0,r.jsx)(n.code,{children:"data.bits"}),".\nIt will remain high and the data will not progress to the next word until the ",(0,r.jsx)(n.code,{children:"ready"})," signal is driven high."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.data.ready"})," (Input): This is driven high iff data can be consumed on the data bus."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.data.bits"})," (Output): The requested data."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Writer Data Channel"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.isFlushed"})," (Output): This is driven high iff there are no writes that have been issued to DRAM but have not\nreturned an acknowledgement."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.data.valid"})," (Input): Drive this high when you wish to write the data on ",(0,r.jsx)(n.code,{children:"data.bits"})," to memory. Drive this\nsignal low when you do not wish to write to memory (including while there is no request active)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.data.ready"})," (Output): This is driven high iff data can be consumed on the data bus."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataChannel.data.bits"})," (Input): The data to be written."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"transaction-waveform",children:"Transaction Waveform"}),"\n",(0,r.jsxs)(n.p,{children:["Below, we show a waveform for an 8-byte transaction on a 4-byte-wide reader channel. Writers operate similarly except for the\n",(0,r.jsx)(n.code,{children:"isFlushed"})," signal."]}),"\n",(0,r.jsx)("p",{align:"center",children:(0,r.jsx)("img",{src:"/Beethoven-Docs/img/figs/read-tx.jpg"})}),"\n",(0,r.jsxs)(n.p,{children:["The request channel first exchanges a handshake with the address and transaction length payloads. Then, after an\nindeterminate amount of time, the data for this transaction is returned. The data is not necessarily returned in\nconsecutive cycles. The next data associated with this transaction is only advanced when valid and reader are high\non the rising clock edge. The data (",(0,r.jsx)(n.code,{children:"data.bits"}),") will be held constant while data.ready is high and data.valid is\ndriven low."]}),"\n",(0,r.jsx)(n.h4,{id:"transaction-parallelism",children:"Transaction Parallelism"}),"\n",(0,r.jsxs)(n.p,{children:["Whereas a user may specify a single logical transaction (i.e., read 1GB of data starting from address ",(0,r.jsx)(n.code,{children:"0x1000"}),"), it is Beethoven's\njob to perform this transaction as quickly as possible. In practice, the FPGA/ASIC's memory link will not be saturated by a single\ntransaction. For our current platforms, the memory link is an AXI channel to a off-chip DRAM module. The AXI protocol provides a\nnumber of ways to saturate the link performance."]}),"\n",(0,r.jsx)(n.p,{children:"First, longer transactions take better advantage of DRAM burst. However, AXI transactions are typically not allowed to cross page\nboundaries (4K). For this reason, our tranascations should be limited to 4KB."}),"\n",(0,r.jsx)(n.p,{children:'If we want to read 1GB, we will need to issue many AXI transactions for one logical transaction. One way to do this is by using\nthe AXI ID specifier to "tag" a transaction. There may be many transactions in flight simultaneously for a single AXI ID. These\ntranasactions are all guaranteed to execute in-order. This applies for both read and writes separately.'}),"\n",(0,r.jsx)(n.p,{children:"This ordering restriction limits our ability to take advantage of DRAM bank-level parallelism. To skirt this restriction,\nwe issue transactions for a single logical transaction using many AXI IDs. This introduces additional complexity to our\nmachinery but, in our experiments, results in higher memory performance.\nTransactions"}),"\n",(0,r.jsx)(n.h3,{id:"on-chip-memory-scratchpad",children:"On-Chip Memory (Scratchpad)"}),"\n",(0,r.jsxs)(n.p,{children:["Beethoven offers two primary interfaces for using on-chip memory. The first is ",(0,r.jsx)(n.code,{children:"Scratchpad"}),", which uses a similar flow to\nthe aforementioned Reader and Writer abstractions. Through this integration to the off-chip memory system, it offers a few\nextra features. For users that want finer-grained control of their on-chip memory cells, there is also ",(0,r.jsx)(n.code,{children:"Memory"}),". This\ntool interacts with the platform-specific backend to instantiate FPGA BRAM and URAM cells or, on ASIC, interact with a\nmemory compiler for instantiating SRAM memory cells. A goal of these interfaces is to help the programmer to map efficiently\nto memory cells without requiring manual planning - although this may occasionally be necessary especially for ASIC\ntargets."]}),"\n",(0,r.jsx)(n.h4,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"config",label:"Scratchpad Configuration",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class ScratchpadConfig(name: String,\n                            dataWidthBits: Int,\n                            nDatas: Int,\n                            nPorts: Int,\n                            latency: Number = 2,\n                            features: ScratchpadFeatures = ScratchpadFeatures())\n"})})}),(0,r.jsx)(s.A,{value:"feature",label:"ScratchpadFeatures",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class ScratchpadFeatures(readOnly: Boolean = false,\n                              supportWriteback: Boolean = false,\n                              supportMemRequest: Boolean = true,\n                              specialization: ScratchpadSpecialization = ScratchpadSpecialization.flatPacked,\n                              nBanks: Int = 1,\n                              writeEnableMuxing: Boolean = false)\n"})})})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"name"}),": Unique identifier for fetching the scratchpad inside the core implementation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataWidthBits"}),": In contrast to the byte-level precision of readers and writers, ",(0,r.jsx)(n.code,{children:"Scratchpad"})," uses bit-widths."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nDatas"}),": the number of datums/rows in the memory array."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nPorts"}),": the number of read-write ports to the memory array (maximum of two is recommended for mapping to BRAM/URAM)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"latency"}),": The latency of a read operation. FPGA memories can be cascaded to larger memories at the cost of latency."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"features"}),": Scratchpads can be customized in a number of ways, but we provide a sensible default configuration that\nshould only need to be changed in special circumstances.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"readOnly"})," - ",(0,r.jsx)(n.strong,{children:"[Default=false]"}),": when enabled, all user-accessible ports will be read-only. This can allow for the use of Simple-Dual-Port\nBRAM functionalities in FPGA."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"supportWriteback"})," - ",(0,r.jsx)(n.strong,{children:"[Default=false]"}),': when enabled, we elaborate a "writeback" engine inside scratchpad and a\ncorresponding port in the request object. This allows the programmer to writeback the contents of the scratchpad\nto memory using a simple request handshake instead of needing to handle it themselves.']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"supportMemRequest"})," - ",(0,r.jsx)(n.strong,{children:"[Default=true]"}),": when enabled, we allow the user to initialize the scratchpad contents from\nexternal memory. Like ",(0,r.jsx)(n.code,{children:"supportWriteback"}),", this elaborates a corresponding port in the request channel."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"specialization"})," - ",(0,r.jsx)(n.strong,{children:"[Default=flatPacked]"}),": because scratchpads operate at bit-granularity, but underlying readers\nand writers used for initialization and writeback use byte-granularity, we need to know how to unpack bits from\npayloads that may not align to data boundary.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"flatPacked"})," - this assumes that the number of bits are power-of-two byte-aligned so there is really not much\nunpacking that needs to be done."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"PackedSubword"})," - in other cases, the number of bits do not align to a byte boundary and so we introduce this\nalternative strategy. There is still some memory overhead here, but it can be minimized. See\n",(0,r.jsx)(n.a,{href:"/Beethoven/HW/#packed-subword-scratchpad",children:"here"})," for the specification."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nBanks"})," - ",(0,r.jsx)(n.strong,{children:"[Default=1]"}),":  For deep, narrow memories, you may want to make better use of memory cells by putting more than one data\non a row. You can increase this parameter to control the number of datas per row."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"writeEnableMuxing"})," - ",(0,r.jsx)(n.strong,{children:"[Default=false]"}),": You can enable byte-wise write enable on the data port using this."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["To retrieve the scratchpad inside your accelerator core, use ",(0,r.jsx)(n.code,{children:"getScratchpad(name: String)"}),"."]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"fsp",label:"Fetch a Scratchpad",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"def getScratchpad(name: String): ScratchpadModuleChannel\n"})})}),(0,r.jsx)(s.A,{value:"spret",label:"Scratchpad Channel Type",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class ScratchpadModuleChannel(\n    requestChannel: ScratchpadMemReqPort,\n    dataChannels: Seq[ScratchpadDataPort])\n"})})}),(0,r.jsx)(s.A,{value:"memreq",label:"ScratchpadMemReqPort",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"class ScratchpadMemReqPort(...)(implicit p: Parameters) extends Bundle {\n  val init, writeback = Flipped(Decoupled(new Bundle() {\n    val memAddr = Address()\n    // scratchpad index to start filling from\n    val scAddr = UInt(log2Up(nDatas).W)\n    // number of bytes from memory to read in\n    val len = UInt(Address.addrBits().W)\n  }))\n}\n"})})}),(0,r.jsx)(s.A,{value:"dat",label:"ScratchpadDataPort",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"class ScratchpadDataPort(...) extends ScratchpadPort {\n  // request to read/write from scratchpad\n  val req = Flipped(Decoupled(new Bundle() {\n    // index of the read\n    val addr = UInt(scReqBits.W)\n    // data input (if writing)\n    val data = UInt(dataWidthBits.W)\n    // active high, write enable\n    val write_enable = Bool()\n  }))\n  // result of the read with an accompanying valid bit\n  val res = ValidIO(UInt(dataWidthBits.W))\n"})})})]}),"\n",(0,r.jsx)(n.p,{children:"Like readers and writers, fetching a scratchpad requires the name it's associated with from the configuration.\nHowever, the request and data channels work differently for the case of on-chip memory.\nThe memory request port allows the user to initialize the scratchpad with contents from memory, and the writeback\nport allows the user to write back the contents of the scratchpad to memory. When each of these transactions has\ncompleted, the ready signal for each of these signals will be driven high."}),"\n",(0,r.jsxs)(n.p,{children:["To access the data inside the scratchpad, use the ",(0,r.jsx)(n.code,{children:"dataChannels"}),". The number of data channels is specified in the\nconfiguration as ",(0,r.jsx)(n.code,{children:"nPorts"}),". The input handshake uses both ready/valid. In some circumstances, the scratchpad may\nnot be ready to be ready to accept a request on a certain port. For instance, if the initialization/writeback\nroutines are in-progress, then one of the ports will be busy and unable to service reads/writes from the\nprogrammer."]}),"\n",(0,r.jsx)(n.p,{children:"The data output from a scratchpad read has a delay corresponding to the latency given in the scratchpad configuration.\nA valid signal accompanies the data. The scratchpad does not have a ready signal for the data_out and it must\nbe consumed when the data is valid."}),"\n",(0,r.jsx)(n.h3,{id:"on-chip-memory-user-managed",children:"On-Chip Memory (User-Managed)"}),"\n",(0,r.jsxs)(n.p,{children:["For instantiating memory cells that are more directly-managed by the user, we provide the ",(0,r.jsx)(n.code,{children:"Memory"})," interface.\nOn FPGA, this will instantiate vendor-provided templates for predictably mapping to memory cells, and for ASIC\ntargets, this will inspect the specified backend for a memory compiler. We provide more details for our ASIC\nmemory compiler support ",(0,r.jsx)(n.a,{href:"/Beethoven/HW/asic-memory-compiler",children:"here"}),"."]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"mem",label:"Memory Instantiation",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"Memory(latency: Int,\n    dataWidth: Int,\n    nRows: Int,\n    nReadPorts: Int,\n    nWritePorts: Int,\n    nReadWritePorts: Int,\n    withWriteEnable: Boolean = false,\n    debugName: Option[String] = None,\n    allowFallbackToRegister: Boolean = true)       \n"})})}),(0,r.jsx)(s.A,{value:"memintf",label:"Memory IOs",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"class MemoryIOBundle(...) extends Bundle {\n    val addr = Input(Vec(nPorts, UInt(addrBits.W)))\n    val data_in = Input(Vec(nPorts, UInt(dataWidth.W)))\n    val data_out = Output(Vec(nPorts, UInt(dataWidth.W)))\n\n    val chip_select = Input(Vec(nPorts, Bool()))\n    val read_enable = Input(Vec(nPorts, Bool()))\n    // if byte-wise write-enable\n    val write_enable = Input(Vec(nPorts, UInt((dataWidth / 8).W)))\n    // if global write-enable\n    val write_enable = Input(Vec(nPorts, Bool()))\n\n    val clock = Input(Bool())\n\n    def getReadPortIdx(idx: Int): Int\n    def getWritePortIdx(idx: Int): Int\n    def getReadWritePortIdx(idx: Int): Int \n\n    def initLow(clock: Clock): Unit\n}\n"})})})]}),"\n",(0,r.jsx)(n.p,{children:"Memory parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"latency"}),": Like scratchpads, user-managed memory also takes a latency parameter. For FPGAs, the use of this\nis straightforward. For ASICs, we cascade memory cells to a similar effect (see ",(0,r.jsx)(n.a,{href:"/Beethoven/HW/asic-memory-compiler",children:"here"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dataWidth"}),": bit-width of the memory"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nRows"}),": number of rows in the memory"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nReadPorts"}),", ",(0,r.jsx)(n.code,{children:"nWritePorts"}),", ",(0,r.jsx)(n.code,{children:"nReadWritePorts"}),": the number of each port to elaborate a memory for. For FPGA,\nthere are special cases (e.g., SDP BRAMs) where using read-only and write-only ports can provide different\nresults."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"withWriteEnable"}),": by default, this is disabled. When enabled, the user will be provided a byte-wise write\nenable signal as opposed to a global write enable."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"debugName"}),": the user can provide a name to annotate their memories by in the resulting RTL."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"allowFallbackToRegister"}),": if the platform's supported memories do not allow for the requested configuration (e.g., too many\nports), Beethoven will elaborate a register-based memory as a fallback routine. If you wish Beethoven to throw an error\nyou can disable this."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The IOs for the memory are platform-agnostic and may, in reality, drive nothing if the signals are not used\non a specific platform. To identify which of the IOs correspond to the read/write/readwrite channels requested, use\nthe ",(0,r.jsx)(n.code,{children:"get<>PortIdx(idx)"})," methods. For instance:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"val my_memory = Memory(...,\n    nReadPorts = 2,\n    nWritePorts = 3,\n    nReadWritePorts = 5,\n    ...)\n// tie off signals to make memory inactive by default\nmy_memory.init_low(clock)\nval read_port_A = my_memory.getReadPortIdx(0)\nval read_port_B = my_memory.getReadPortIdx(1)\n// read ports can now be accessed using\nmy_memory.data_out(read_port_A)\n\n// we can get port indices for our 0th, 1st, and 2nd write port\nval write_port_C = my_memory.getWritePortIdx(0)\nval write_port_D = my_memory.getWritePortIdx(1)\nval write_port_E = my_memory.getWritePortIdx(2)\nmy_memory.data_in(write_port_D) := DontCare\n"})}),"\n",(0,r.jsxs)(n.p,{children:["We provide a ",(0,r.jsx)(n.code,{children:"init_low(clock: Clock)"})," method to initialize the memory inputs to inactive.\n",(0,r.jsx)(n.strong,{children:"All input signals to the memories are active-high, even if the underlying memory uses active-low inputs."}),"\nThe latency of a write operation is always 1-cycle, even if the memory's specified latency is higher."]}),"\n",(0,r.jsx)(n.h2,{id:"host-interface",children:"Host Interface"}),"\n",(0,r.jsxs)(n.p,{children:["Users specify host-facing interfaces with ",(0,r.jsx)(n.code,{children:"BeethovenIO()"}),".\n",(0,r.jsx)(n.code,{children:"BeethovenIO"})," takes in an ",(0,r.jsx)(n.code,{children:"AccelCommmand"})," and ",(0,r.jsx)(n.code,{children:"AccelResponse"})," implementation and generates host C++ linkage for\ncommunicating with the accelerator core. You can instantiate multiple ",(0,r.jsx)(n.code,{children:"BeethovenIO()"})," and it will generate\nmultiple host C++ interfaces."]}),"\n",(0,r.jsx)(n.h4,{id:"accelcommand",children:"AccelCommand"}),"\n",(0,r.jsxs)(n.p,{children:["While we have supported arbitrary types inside ",(0,r.jsx)(n.code,{children:"AccelCommand"})," in the past, maintaining the transformation between\narbitrary Chisel types and C++ is complex so we recommend using basic types for the most consistent results. The\nrecommended types are, ",(0,r.jsx)(n.code,{children:"UInt"}),", ",(0,r.jsx)(n.code,{children:"SInt"}),", ",(0,r.jsx)(n.code,{children:"Bool"}),", and ",(0,r.jsx)(n.code,{children:"Address"}),". These types may be at most 128b long. There is no\nlimit to the number of elements in the ",(0,r.jsx)(n.code,{children:"AccelCommand"}),". We discuss memory allocation for the accelerator and the\nassociated ",(0,r.jsx)(n.code,{children:"Address"})," type ",(0,r.jsx)(n.a,{href:"/Beethoven/SW/#beethoven-runtime",children:"here"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Beethoven's host->HW interface is, for our current platforms, an 32-bit AXI-Lite port. For legacy reasons, we\nencode commands using the RISC-V RoCC instruction format. RoCC instructions are a 32-bit instruction (which we\npack with routing information) and two 64-bit payloads. We pack the user-specified operands without fragmentation\ninto these payloads. Communicating a single instruction takes ~10\xb5s over PCIE. Therefore, expect a multiple of\nthis delay for the number of 128-bit payloads necessary to communicate your ",(0,r.jsx)(n.code,{children:"AccelCommand"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"AccelCommand"})," takes a name as input. This will be used to construct the C++ host binding for this command.\nThe accelerator will be accessible from host as ",(0,r.jsx)(n.code,{children:"<Core-Name>::<Command-Name>"}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"accelresponse",children:"AccelResponse"}),"\n",(0,r.jsxs)(n.p,{children:["Responses are optional in Beethoven and are paired with a command. If a core does not respond to the core for\na given command, then the ",(0,r.jsx)(n.code,{children:"BeethovenIO"})," does not need to specify a response. To return an empty acknowledgement\nof completion for a command, you can use ",(0,r.jsx)(n.code,{children:"EmptyAccelResponse()"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Beethoven also allows you to return a response with a payload up to 64-bits wide. For longer payloads, we\nrecommend writing results to memory."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"val my_io = BeethovenIO(...,\n    AccelResponse(responseName) {\n        ...\n    })\n"})}),"\n",(0,r.jsx)(n.p,{children:"The user provides a name for the accelerator response. This response will be the name of the response struct type.\nFor instance:"}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"cmd",label:"BeethovenIO",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'// inside MyCore\nval my_io = BeethovenIO(\n    new AccelCommand("my_command"){...},\n    new AccelResponse("my_response_t") {\n        val a = UInt(4.W)\n        val b = SInt(16.W)\n    })\n'})})}),(0,r.jsx)(s.A,{value:"cpp",label:"Generated C++",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:"namespace MyCore {\n    beethoven::response_handle<my_response_t> my_command(...);\n\n    struct my_response_t {\n        uint8_t a;\n        int16_t b;\n    };\n}\n"})})})]}),"\n",(0,r.jsx)(n.h4,{id:"behavior-of-beethovenio",children:"Behavior of BeethovenIO"}),"\n",(0,r.jsx)(n.p,{children:"Both the command and response are coupled with ready/valid handshakes.\nFor the command, the user drives the ready signal and for the response, the user drives the valid signal.\nThe core should not drive the ready signal high until it has returned a corresponding response (if applicable).\nThe core may accept commands without a corresponding response while processing another command.\nThe core should not drive the response valid high while it is not processing a command."}),"\n",(0,r.jsx)(n.h2,{id:"configuration--build",children:"Configuration + Build"}),"\n",(0,r.jsxs)(n.p,{children:["An accelerator or a piece of an accelerator is described using an ",(0,r.jsx)(n.code,{children:"AcceleratorConfig"}),". An ",(0,r.jsx)(n.code,{children:"AcceleratorConfig"}),"\nis defined as one of a list of ",(0,r.jsx)(n.code,{children:"AcceleratorSystemConfig"}),". ",(0,r.jsx)(n.code,{children:"AcceleratorConfigs"})," can be concatenated with the\n",(0,r.jsx)(n.code,{children:"++"})," operator to conjoin accelerator descriptions."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class AcceleratorSystemConfig(\n    nCores: Int,\n    name: String,\n    moduleConstructor: ModuleConstructor,\n    memoryChannelConfig: List[MemChannelConfig] = List(),\n    canReceiveSoftwareCommands: Boolean = true,\n    canIssueCoreCommandsTo: Seq[String] = Seq.empty,\n    canSendDataTo: Seq[String] = Seq.empty\n)\n"})}),"\n",(0,r.jsx)(n.p,{children:'A "System" is a group of identical cores, which are identifiable by a unique name. This is the name that will\nform the namespace in the generated C++ linkage. The user may specify an arbitrary number of cores.'}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"An Aside:"}),"  Beethoven is built on top of ",(0,r.jsx)(n.a,{href:"https://github.com/chipsalliance/rocket-chip",children:"RocketChip"})," for use of its protocol\n",(0,r.jsx)(n.a,{href:"https://github.com/chipsalliance/rocket-chip/blob/master/docs/src/diplomacy/adder_tutorial.md",children:"Diplomacy"})," framework.\nBecause of this, you may see a ",(0,r.jsx)(n.code,{children:"Parameters"})," object floating around in various interfaces. ",(0,r.jsx)(n.code,{children:"Parameters"})," is a\nmap object that allows us to look up various details about the current build without needing to pass around hundreds of\nof arguments. ",(0,r.jsx)(n.code,{children:"implicit"})," is a Scala keyword that inspects the caller's scope for an implicit parameter of a given name and\nautomatically passes in the parameter if it finds one."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"moduleConstructor"})," exposes the constructor of your accelerator core to the build system. There are multiple\noptions. There are two ways to do this. First, if you are developing your top-level module in Chisel, then you will use\n",(0,r.jsx)(n.code,{children:"ModuleBuilder"})," which takes in a function that maps a ",(0,r.jsx)(n.code,{children:"Parameters"})," object to an Accelerator Core. This is the most common\nuse-case. If you want nothing to do with Chisel, then you can also use ",(0,r.jsx)(n.code,{children:"BlackboxBuilderCustom"})," to generate a Verilog shell\nwith a custom command/response interface."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"case class BlackboxBuilderCustom(coreCommand: AccelCommand, coreResponse: AccelResponse) extends ModuleConstructor\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"memoryChannelConfig"})," is where you provide a list of memory interfaces (e.g., Readers, Writers) for a core in this sytem.\nIf you intend for an accelerator core to only be internally visible (other cores can communicate with it but not the host,\nthen you can specify this using ",(0,r.jsx)(n.code,{children:"canReceiveSoftwareCommands"}),". In such circumstances, we also need to define the communication\ntopology for these intercommunicating cores. You specify the ways in which cores may communicate with other systems using\n",(0,r.jsx)(n.code,{children:"canIssueCoreCommandsTo"})," and ",(0,r.jsx)(n.code,{children:"canSendDataTo"})," and providing the names of the systems."]}),"\n",(0,r.jsx)(n.h4,{id:"building-your-accelerator",children:"Building your Accelerator"}),"\n",(0,r.jsxs)(n.p,{children:["Now that you've constructed an accelerator configuration, you can use a ",(0,r.jsx)(n.code,{children:"BeethovenBuild"})," object to construct your accelerator\nfor a given platform like so."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"object MyAcceleratorBuild extends BeethovenBuild(new MyAcceleratorConfig,\n    buildMode = <BuildMode>,\n    platform = <Your Platform>)\n// you will see 'MyAcceleratorBuild' as an option when you run `sbt run` in the top directory.\n"})}),"\n",(0,r.jsxs)(n.p,{children:["First, you must specify which platform you are building your hardware for. We have currently two well-supported FPGA platforms,\nthe ",(0,r.jsx)(n.a,{href:"https://www.amd.com/en/products/system-on-modules/kria/k26/kv260-vision-starter-kit.html",children:"Kria KV260"}),", and the AWS F1/F2\ncloud FPGA instances."]}),"\n",(0,r.jsxs)(n.p,{children:["Beethoven has two build modes: ",(0,r.jsx)(n.code,{children:"BuildMode.Synthesis"})," and ",(0,r.jsx)(n.code,{children:"BuildMode.Simulation"}),". When building for synthesis, we generate the\nhardware and run a platform-specific"]}),"\n",(0,r.jsx)(n.h2,{id:"platforms",children:"Platforms"}),"\n",(0,r.jsx)(n.h4,{id:"current-platforms",children:"Current Platforms"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["AWS F1/F2 ",(0,r.jsx)(n.a,{href:"https://aws.amazon.com/ec2/instance-types/f2/",children:"[link]"})," ",(0,r.jsx)(n.a,{href:"https://github.com/aws/aws-fpga",children:"[GitHub]"})," -\nAWS offers cloud-FPGAs at a reasonable hourly price for those who aren't ready to drop $15,000 on a new\ndatacenter FPGA. AWS has recently phased-out use of the F1 platform and we are transferring this functionality over to the F2.\n",(0,r.jsx)(n.a,{href:"/Beethoven/Platform/AWSF",children:"See here"})," for a walkthrough on deploying a design on AWS F2."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-ultrascale-plus-mpsoc.html",children:"Zynq Ultrascale+ Series"})," -\nThe Zynq MPSoCs feature a dual-Core ARM A53 capable of running Linux. We use the ",(0,r.jsx)(n.a,{href:"https://www.amd.com/en/products/system-on-modules/kria/k26/kv260-vision-starter-kit.html",children:"Kria KV260"}),"\nfor our development purposes. ",(0,r.jsx)(n.a,{href:"/Beethoven/Platform/Kria",children:"See here"})," for a walkthrough on deploying a design on Kria."]}),"\n",(0,r.jsx)(n.li,{children:'ASIC Test Chip - We are taping out a chip using Beethoven! Check back in a few months to see if the chip works. If you are\ninterested in this, contact the authors. This functionality is actively in-development and some of the implementation\nin conjunction with Beethoven may require some tinkering to make it "open-source"-able.'}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["If you're interested in developing your own platform, ",(0,r.jsx)(n.a,{href:"/Beethoven/Platform/NewPlatform",children:"read here"}),"."]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},5537:(e,n,a)=>{a.d(n,{A:()=>w});var t=a(6540),r=a(4164),i=a(5627),o=a(6347),s=a(372),l=a(604),c=a(1861),d=a(8749);function h(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:a}=e;return(0,t.useMemo)((()=>{const e=n??function(e){return h(e).map((e=>{let{props:{value:n,label:a,attributes:t,default:r}}=e;return{value:n,label:a,attributes:t,default:r}}))}(a);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,a])}function m(e){let{value:n,tabValues:a}=e;return a.some((e=>e.value===n))}function p(e){let{queryString:n=!1,groupId:a}=e;const r=(0,o.W6)(),i=function(e){let{queryString:n=!1,groupId:a}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:n,groupId:a});return[(0,l.aZ)(i),(0,t.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(r.location.search);n.set(i,e),r.replace({...r.location,search:n.toString()})}),[i,r])]}function f(e){const{defaultValue:n,queryString:a=!1,groupId:r}=e,i=u(e),[o,l]=(0,t.useState)((()=>function(e){let{defaultValue:n,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!m({value:n,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const t=a.find((e=>e.default))??a[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i}))),[c,h]=p({queryString:a,groupId:r}),[f,g]=function(e){let{groupId:n}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,i]=(0,d.Dv)(a);return[r,(0,t.useCallback)((e=>{a&&i.set(e)}),[a,i])]}({groupId:r}),v=(()=>{const e=c??f;return m({value:e,tabValues:i})?e:null})();(0,s.A)((()=>{v&&l(v)}),[v]);return{selectedValue:o,selectValue:(0,t.useCallback)((e=>{if(!m({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),h(e),g(e)}),[h,g,i]),tabValues:i}}var g=a(9136);const v={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=a(4848);function x(e){let{className:n,block:a,selectedValue:t,selectValue:o,tabValues:s}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),d=e=>{const n=e.currentTarget,a=l.indexOf(n),r=s[a].value;r!==t&&(c(n),o(r))},h=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=l.indexOf(e.currentTarget)+1;n=l[a]??l[0];break}case"ArrowLeft":{const a=l.indexOf(e.currentTarget)-1;n=l[a]??l[l.length-1];break}}n?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":a},n),children:s.map((e=>{let{value:n,label:a,attributes:i}=e;return(0,y.jsx)("li",{role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:e=>{l.push(e)},onKeyDown:h,onClick:d,...i,className:(0,r.A)("tabs__item",v.tabItem,i?.className,{"tabs__item--active":t===n}),children:a??n},n)}))})}function b(e){let{lazy:n,children:a,selectedValue:i}=e;const o=(Array.isArray(a)?a:[a]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===i));return e?(0,t.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==i})))})}function j(e){const n=f(e);return(0,y.jsxs)("div",{className:(0,r.A)("tabs-container",v.tabList),children:[(0,y.jsx)(x,{...n,...e}),(0,y.jsx)(b,{...n,...e})]})}function w(e){const n=(0,g.A)();return(0,y.jsx)(j,{...e,children:h(e.children)},String(n))}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>s});var t=a(6540);const r={},i=t.createContext(r);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(i.Provider,{value:n},e.children)}},9329:(e,n,a)=>{a.d(n,{A:()=>o});a(6540);var t=a(4164);const r={tabItem:"tabItem_Ymn6"};var i=a(4848);function o(e){let{children:n,hidden:a,className:o}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,t.A)(r.tabItem,o),hidden:a,children:n})}}}]);